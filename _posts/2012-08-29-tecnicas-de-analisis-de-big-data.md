---
title: "Técnicas de análisis de Big Data"
date: "2012-08-29"
categories: 
  - "big-data"
tags: 
  - "big-data"
  - "inteligengia-artificial"
  - "patrones"
  - "simulaciones"
  - "tecnicas-de-analisis"
  - "testing"
---

Evidentemente cuanta más data tengamos más exhaustivo va a ser nuestro análisis, algunas de estas técnicas pueden ser aplicadas a grupos pequeños, pero todas pueden ser aplicadas al [Big Data](http://rocreguant.com/category/big-data/ "Big Data"). Aquí van los grupos:

- **A/B Testing:** Esto es una de las técnicas que se puede usar con grupos de data pequeños. Se trata de mostrar dos versiones distintas de la web (o de lo que sea) para determinar que variación se adapta mejor a nuestros objetivos.
    
- **Aprendizaje de asociaciones:** Se trata de encontrar relaciones entre datos que nos puedan ser útiles. En el caso de Facebook sería que personas tenemos mas posibilidades de empezar a seguir, pero en caso de Amazon es que producto posiblemente compraremos si hemos realizado un seguido de acciones (por ejemplo que dos productos se suelen comprar a la vez). Sabiendo esto lo pueden poner más fácil a los clientes.
    
- **Clasificación:** Se trata de que la computadora determine a que grupo de data pertenece un nuevo set de data basándose en clasificaciones pasadas y los ejemplos “entrados a mano”. Un ejemplo sería determinar el idioma de un texto basado en ejemplos dados por humanos que si sepan que lengua es. Evidentemente cuanto mayor sea el dato a comparar menos probabilidades de error tendrá.
    
- **Análisis del cluser:** Se trata de reducir el cluster a grupos más pequeños y de ordenarlos de otra forma encontrando similaridades que antes se nos habían pasado por alto. Por ejemplo, que tienen en común una chica de 20 años de Madrid y un hombre sevillano de 40 años? Pues que a los dos les gusta hacer puzzles en su tiempo libre.
    
- **Crowdsourcing:** Es una técnica de recolección de data enviada por un largo grupo de usuarios (de aquí “crowd”). Preguntas a la comunidad y esta te responde. Un ejemplo de esto sería Starbucks que pregunta a los usuarios en que podría mejorar y que nuevos productos debería sacar al mercado.
    
- **Fusión e integración de la data:** A veces hay datos que por si solos no aportan mucho pero combinados con otros ya es otro tema. El GPS de tu móvil sólo dice dónde estás, pero combinado con Twitter puedes encontrar gente nueva, o combinado con un mapa de la zona te ayuda a ubicarte.
    
- **Data mining:** Es un conjunto de técnicas para extraer información útil de grandes cantidades de data y presentarlo de forma que los humanos lo podamos comprender y poder sacar provecho de ello. La data si no se sabe usar por si sola no sirve de nada.
    
- **Aprendizaje predictivo:** Con el uso de modelos predictivos (basados en estadística y machine learning) podemos determinar o intentar predecir el futuro de determinados modelos.
    
- **Algoritmos genéticos:** También conocidos como algoritmos de la evolución sirven para mejorar problemas no lineales. Como dice la teoría de la evolución, “sobrevive el mejor adaptado”, pues este caso vendría a ser el cambio que desarrolla un mejor desempeño.
    
- **Machine learning:** Una parte de este es la inteligencia artificial y se basa en evolucionar su comportamiento basado en datos empíricos.
    
- **Circuitos neuronales:** Recibe este nombre porque se parecen bastante a las conexiones de nuestras neuronas. Esta técnica nos ayuda a buscar patrones no lineales y optimizarlos.
    
- **Análisis de redes:** Es un conjunto de técnicas que permiten encontrar los nodos de más influencia, la dirección de los datos. Esto permite conocer a los influencers (para estrategias de marketing) o para identificar los cuellos de botella.
    
- **Optimización:** Los algoritmos genéticos son una de estas técnicas, sirven para mejorar el proceso en función el coste, velocidad...
    
- **Reconocimiento de patrones:** Es una de las partes de clasificación. Dada una entrada, da una salida siguiendo el mismo algoritmo.
    
- **Predecir modelos:** Se trata de crear un modelo matemático con la mayor probabilidad de predecir la salida. Calculan la probabilidad de que pase una determinada cosa.
    
- **Regresión:** Es una de las técnicas para predecir modelos, se trata de que dadas algunas constantes, calcular que pasa cuando se modifican las variables.
    
- **Simulación:** Dadas las probabilidades de todas las variables calcula que pasa en cada escenario para unos datos concretos. Haciendo así ver como puede reaccionar nuestro (p.ej.) material, a determinadas condiciones.
    

Uf, este ha sido un post muy intenso. Me ha costado lo suyo pero creo que ha salido bastante completo. Espero que os haya gustado, para cualquier cosa ya sabéis, comentario! ;)
